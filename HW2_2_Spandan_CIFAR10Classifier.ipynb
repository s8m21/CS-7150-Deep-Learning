{"cells":[{"cell_type":"markdown","metadata":{"id":"0ff28b42"},"source":["This can be run [run on Google Colab using this link](https://colab.research.google.com/github/CS7150/CS7150-Homework-2/blob/main/HW2_2_CIFAR10Classifier.ipynb)\n","\n","\u003cfont size='6'\u003e**Homework 2.2: Neural Network CIFAR-10 Classification**\u003c/font\u003e"]},{"cell_type":"markdown","metadata":{"id":"0ef1d8e6"},"source":["\u003cfont size='5'\u003e**Overview**\u003c/font\u003e\n","\n","In this CS7150 assignment, our objective is to build a neural network featuring two fully-connected layers designed for classification purposes. We will evaluate the performance of this neural network by testing it on the CIFAR-10 dataset.\n","\n","This assignment adheres to a standard classification setup, which encompasses the use of a dataloader to load labeled image data in a natural form and training the model in a minibatch-based fashion.\n","\n","**Your assignment**: Your responsibility throughout this notebook is to thoroughly review the content and address all the conceptual and technical questions identified within the sections marked with \"Task\" headers and \"TODO:\" comments in the code."]},{"cell_type":"markdown","metadata":{"id":"ih2KqUX1Aj1G"},"source":["\u003cfont size='5'\u003e**I) Setup**\u003c/font\u003e"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1bGxnahJAlmm"},"outputs":[],"source":["import os\n","import torch\n","from torch import nn\n","from torchvision.datasets import CIFAR10\n","from torchvision.transforms import Compose, ToTensor\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"075f340c"},"source":["\u003cfont size='4'\u003e**Device Setup**\u003c/font\u003e"]},{"cell_type":"markdown","metadata":{"id":"33798935"},"source":["\n","We aim to enable model training on a GPU to expedite our computations. First, we'll check whether torch.cuda is accessible; if it is, we will utilize the GPU; otherwise, we will continue to using the CPU."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1696556463179,"user":{"displayName":"Spandan Maaheshwari","userId":"08697071118653585995"},"user_tz":240},"id":"c9a41951","outputId":"415720c5-0f3e-47e4-bc19-d281c81228b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda device\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"]},{"cell_type":"markdown","metadata":{"id":"2d6db073"},"source":["\u003cfont size='4'\u003e**Loading CIFAR-10 Data**\u003c/font\u003e"]},{"cell_type":"markdown","metadata":{"id":"af842fd2"},"source":["The CIFAR-10 dataset comprises a collection of 60,000 32x32 color images distributed across ten distinct classes. These classes correspond to various objects and include airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. Within each class, there are precisely 6,000 images."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19880,"status":"ok","timestamp":1696556483049,"user":{"displayName":"Spandan Maaheshwari","userId":"08697071118653585995"},"user_tz":240},"id":"0c9c37c7","outputId":"bd9dfc61-a906-4296-cacb-082cd66c259a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to cifar10_data/cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [00:14\u003c00:00, 11727822.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting cifar10_data/cifar-10-python.tar.gz to cifar10_data\n","Files already downloaded and verified\n","Datatype of the dataset object: \u003cclass 'torchvision.datasets.cifar.CIFAR10'\u003e\n","Number of samples in training data: 50000\n","Number of samples in test data: 10000\n","Format of the dataset: \n"," Dataset CIFAR10\n","    Number of datapoints: 50000\n","    Root location: cifar10_data\n","    Split: Train\n","    StandardTransform\n","Transform: Compose(\n","               ToTensor()\n","           )\n"]}],"source":["# downloading cifar10 into folder\n","data_dir = 'cifar10_data' # make sure that this folder is created in your working dir\n","\n","#TODO: Fill out train_data and test_data variables using CIFAR10 (i.e., torchvision.datasets.CIFAR)\n","train_data = CIFAR10(data_dir, train=True, download=True, transform=Compose([ToTensor()]))\n","test_data = CIFAR10(data_dir, train=False, download=True, transform=Compose([ToTensor()]))\n","#train_data = None\n","#test_data = None\n","print(f'Datatype of the dataset object: {type(train_data)}')\n","# check the length of dataset\n","print(f'Number of samples in training data: {len(train_data)}')\n","print(f'Number of samples in test data: {len(test_data)}')\n","# Check the format of dataset\n","print(f'Format of the dataset: \\n {train_data}')"]},{"cell_type":"markdown","metadata":{"id":"507b2b64"},"source":["### \u003cfont size='4'\u003e**Displaying Loaded Dataset**\u003c/font\u003e"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":438},"executionInfo":{"elapsed":674,"status":"ok","timestamp":1696556483712,"user":{"displayName":"Spandan Maaheshwari","userId":"08697071118653585995"},"user_tz":240},"id":"22b496c9","outputId":"9fbdce1b-1508-47a4-fa9f-8ea1cae32987"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 640x480 with 6 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["fig = plt.figure()\n","for i in range(6):\n","  plt.subplot(2, 3, i+1)\n","  plt.tight_layout()\n","  plt.imshow(train_data[i][0][0], cmap='gray', interpolation='none')\n","  plt.title(\"Class Label: {}\".format(train_data[i][1]))\n","  plt.xticks([])\n","  plt.yticks([])"]},{"cell_type":"markdown","metadata":{"id":"f4b11341"},"source":["## \u003cfont size='5'\u003e**II) Building a Neural Network**\u003c/font\u003e"]},{"cell_type":"markdown","metadata":{"id":"a180f9c7"},"source":["### \u003cfont size='4'\u003e**1) Defining `CIFAR10Classifier` class**\u003c/font\u003e"]},{"cell_type":"markdown","metadata":{"id":"003e4e25"},"source":["\u003cfont size='4' color='Red'\u003eTask 1.1 - Defining `CIFAR10Classifier` class (4 points)\u003c/font\u003e\n","\n","In the following class, make adjustments to the following attributes: flatten, hidden_size, class_size, and linear_relu_stack. Ensure that the linear_relu_stack consists of a minimum of two linear layers combined with a non-linear activation layer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bd2c5289"},"outputs":[],"source":["class CIFAR10Classifier(nn.Module):\n","    def __init__(self):\n","        super(CIFAR10Classifier, self).__init__()\n","        ########################################################################\n","        # TODO: Complete the following variables as instructed earlier\n","        ########################################################################\n","        self.flatten = nn.Flatten()\n","        self.hidden_size = 128\n","        self.class_size = 10\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(32*32*3, self.hidden_size),\n","            nn.ReLU(),\n","            nn.Linear(self.hidden_size, self.class_size)\n","        )\n","        ########################################################################\n","        #                             END OF YOUR CODE                         #\n","        ########################################################################\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits"]},{"cell_type":"markdown","metadata":{"id":"720bfbd5"},"source":["### \u003cfont size='4'\u003e**2) Training a Neural Network**\u003c/font\u003e"]},{"cell_type":"markdown","metadata":{"id":"fU8M2hZKKIqf"},"source":["\u003cfont size='4' color='Red'\u003eTask 1.2 - Defining parameters (3 points)\u003c/font\u003e"]},{"cell_type":"markdown","metadata":{"id":"nWQyEYmrDSV3"},"source":["Let's create an instance of `CIFAR10Classifier` and move it to the device. After doing so, we define the following hyperparameters for training:\n","\n","- **Number of Epochs**: This signifies the number of iterations over the dataset.\n","- **Batch Size**: It represents the number of data samples that propagate through the network before parameter updates.\n","- **Learning Rate**: This parameter determines the extent of model parameter updates during each batch/epoch. Smaller values lead to slower learning, while larger values may introduce instability during training.\n","\n","**Your Task**:\n","\n","1. Set `learning_rate` to 1e-3, `batch_size` to 64, and `epochs` to 10 initially. Experiment with different values and retain the final choices that yield the highest testing accuracy.\n","\n","2. Select an appropriate loss function. You should experiment with different options, such as `CrossEntropyLoss()`, `MSELoss()`, and any others, and choose the one that best suits the task.\n","\n","3. Define the `optimizer` variable using any optimizer function (e.g., SGD, Adam, etc.). Be sure to explore different parameter values within the chosen optimizer function.\n","\n","4. Remember to record your ultimate choices for each variable that contribute to achieving the best performance for your `CIFAR10Classifier`. To receive full credit for this assignment, your model should attain a classification accuracy of over 50% on the test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WSTgaNxI9c5f"},"outputs":[],"source":["model = CIFAR10Classifier().to(device)\n","model.requires_grad_(True)\n","\n","########################################################################\n","# TODO: Complete the following variables as instructed earlier\n","########################################################################\n","\n","learning_rate = 1e-4\n","batch_size = 32\n","epochs = 35\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","\n","########################################################################\n","#                             END OF YOUR CODE                         #\n","########################################################################"]},{"cell_type":"markdown","metadata":{"id":"556ce020"},"source":["### \u003cfont size='4'\u003e**3) Train Loop**\u003c/font\u003e"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0cf5e0b8"},"outputs":[],"source":["train_dataloader = DataLoader(train_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"a43130c9"},"source":["In the above cell, we used a Dataloader to create batches for training and testing data. For each batch of size indicated in the batch_size hyperparameter, we perform backprop and update the model parameters' weights and biases.\n","\n","In the following cell, we define our train_loop."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fa4eeed5"},"outputs":[],"source":["def train_loop(dataloader, model, loss_fn, optimizer, print_log=True):\n","    size = len(dataloader.dataset)\n","    correct = 0\n","    training_acc = 0\n","    training_loss = 0\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Compute prediction and loss\n","        pred = model(X.to(device))\n","        loss = loss_fn(pred, y.to(device))\n","        correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        loss, current = loss.item(), batch * len(X)\n","        training_loss = loss\n","        if (print_log==True) and (batch % 100 == 0):\n","            print(f\"\"\"Training loop: loss: {loss:\u003e7f}  [{current:\u003e5d}/{size:\u003e5d}]\"\"\")\n","    correct /= size\n","    training_acc = 100*correct\n","    if (print_log==True):\n","        print(f\"\"\"Training Accuracy: {training_acc:\u003e0.1f}%\"\"\")\n","    return training_acc, training_loss"]},{"cell_type":"markdown","metadata":{"id":"2b6072ee"},"source":["### \u003cfont size='4'\u003e**4) Test Loop**\u003c/font\u003e"]},{"cell_type":"markdown","metadata":{"id":"ba22bb45"},"source":["In the test loop, we iterate over the test dataset to check if model performance is improving."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a05d6353"},"outputs":[],"source":["def test_loop(dataloader, model, loss_fn, print_log=True):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    test_loss, correct = 0, 0\n","\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            pred = model(X.to(device))\n","            test_loss += loss_fn(pred, y.to(device)).item()\n","            correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\n","\n","    test_loss /= num_batches\n","    correct /= size\n","    testing_acc = 100*correct\n","    if (print_log==True):\n","        print(f\"Testing Accuracy: {testing_acc:\u003e0.1f}%, Avg loss: {test_loss:\u003e8f} \\n\")\n","    return testing_acc, test_loss"]},{"cell_type":"markdown","metadata":{"id":"d10b7c82"},"source":["### \u003cfont size='4'\u003e**5) Running the loops**\u003c/font\u003e"]},{"cell_type":"markdown","metadata":{"id":"4245bd36"},"source":["We run our loops for a certain number of times, which is indicated in the 'epoch' hyperparameter that we defined earlier. In the following cell, we run both our training and testing loop to see how our training and testing accuracies change over time."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"836fc7f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1\n","-------------------------------\n","Training loop: loss: 2.276124  [    0/50000]\n","Training loop: loss: 2.141193  [ 3200/50000]\n","Training loop: loss: 2.026162  [ 6400/50000]\n","Training loop: loss: 2.051528  [ 9600/50000]\n","Training loop: loss: 1.853355  [12800/50000]\n","Training loop: loss: 1.943641  [16000/50000]\n","Training loop: loss: 2.007773  [19200/50000]\n","Training loop: loss: 1.861061  [22400/50000]\n","Training loop: loss: 1.946546  [25600/50000]\n","Training loop: loss: 1.957826  [28800/50000]\n","Training loop: loss: 1.888748  [32000/50000]\n","Training loop: loss: 1.908278  [35200/50000]\n","Training loop: loss: 2.189140  [38400/50000]\n","Training loop: loss: 1.718783  [41600/50000]\n","Training loop: loss: 1.905380  [44800/50000]\n","Training loop: loss: 2.151713  [48000/50000]\n","Training Accuracy: 30.7%\n","Testing Accuracy: 36.0%, Avg loss: 1.833314 \n","\n","Epoch 2\n","-------------------------------\n","Training loop: loss: 1.844321  [    0/50000]\n","Training loop: loss: 1.867235  [ 3200/50000]\n","Training loop: loss: 1.749061  [ 6400/50000]\n","Training loop: loss: 1.817583  [ 9600/50000]\n","Training loop: loss: 1.553297  [12800/50000]\n","Training loop: loss: 1.751252  [16000/50000]\n","Training loop: loss: 1.861391  [19200/50000]\n","Training loop: loss: 1.721009  [22400/50000]\n","Training loop: loss: 1.849052  [25600/50000]\n","Training loop: loss: 1.762905  [28800/50000]\n","Training loop: loss: 1.782056  [32000/50000]\n","Training loop: loss: 1.810344  [35200/50000]\n","Training loop: loss: 2.088676  [38400/50000]\n","Training loop: loss: 1.651725  [41600/50000]\n","Training loop: loss: 1.823628  [44800/50000]\n","Training loop: loss: 2.153439  [48000/50000]\n","Training Accuracy: 37.0%\n","Testing Accuracy: 39.3%, Avg loss: 1.748241 \n","\n","Epoch 3\n","-------------------------------\n","Training loop: loss: 1.785881  [    0/50000]\n","Training loop: loss: 1.791702  [ 3200/50000]\n","Training loop: loss: 1.653955  [ 6400/50000]\n","Training loop: loss: 1.700593  [ 9600/50000]\n","Training loop: loss: 1.476477  [12800/50000]\n","Training loop: loss: 1.628541  [16000/50000]\n","Training loop: loss: 1.785841  [19200/50000]\n","Training loop: loss: 1.689821  [22400/50000]\n","Training loop: loss: 1.744395  [25600/50000]\n","Training loop: loss: 1.657600  [28800/50000]\n","Training loop: loss: 1.740918  [32000/50000]\n","Training loop: loss: 1.766558  [35200/50000]\n","Training loop: loss: 1.998318  [38400/50000]\n","Training loop: loss: 1.610989  [41600/50000]\n","Training loop: loss: 1.756345  [44800/50000]\n","Training loop: loss: 2.130473  [48000/50000]\n","Training Accuracy: 39.6%\n","Testing Accuracy: 41.2%, Avg loss: 1.693801 \n","\n","Epoch 4\n","-------------------------------\n","Training loop: loss: 1.759849  [    0/50000]\n","Training loop: loss: 1.747152  [ 3200/50000]\n","Training loop: loss: 1.612789  [ 6400/50000]\n","Training loop: loss: 1.629978  [ 9600/50000]\n","Training loop: loss: 1.458256  [12800/50000]\n","Training loop: loss: 1.543779  [16000/50000]\n","Training loop: loss: 1.765086  [19200/50000]\n","Training loop: loss: 1.663593  [22400/50000]\n","Training loop: loss: 1.664422  [25600/50000]\n","Training loop: loss: 1.592399  [28800/50000]\n","Training loop: loss: 1.714056  [32000/50000]\n","Training loop: loss: 1.733131  [35200/50000]\n","Training loop: loss: 1.925793  [38400/50000]\n","Training loop: loss: 1.577907  [41600/50000]\n","Training loop: loss: 1.711845  [44800/50000]\n","Training loop: loss: 2.099682  [48000/50000]\n","Training Accuracy: 41.4%\n","Testing Accuracy: 42.5%, Avg loss: 1.654938 \n","\n","Epoch 5\n","-------------------------------\n","Training loop: loss: 1.747582  [    0/50000]\n","Training loop: loss: 1.713057  [ 3200/50000]\n","Training loop: loss: 1.592914  [ 6400/50000]\n","Training loop: loss: 1.572991  [ 9600/50000]\n","Training loop: loss: 1.426724  [12800/50000]\n","Training loop: loss: 1.477167  [16000/50000]\n","Training loop: loss: 1.750869  [19200/50000]\n","Training loop: loss: 1.629908  [22400/50000]\n","Training loop: loss: 1.607020  [25600/50000]\n","Training loop: loss: 1.545741  [28800/50000]\n","Training loop: loss: 1.696338  [32000/50000]\n","Training loop: loss: 1.700433  [35200/50000]\n","Training loop: loss: 1.881738  [38400/50000]\n","Training loop: loss: 1.520208  [41600/50000]\n","Training loop: loss: 1.679537  [44800/50000]\n","Training loop: loss: 2.080303  [48000/50000]\n","Training Accuracy: 42.7%\n","Testing Accuracy: 43.8%, Avg loss: 1.625142 \n","\n","Epoch 6\n","-------------------------------\n","Training loop: loss: 1.732161  [    0/50000]\n","Training loop: loss: 1.667171  [ 3200/50000]\n","Training loop: loss: 1.586842  [ 6400/50000]\n","Training loop: loss: 1.527545  [ 9600/50000]\n","Training loop: loss: 1.382364  [12800/50000]\n","Training loop: loss: 1.425745  [16000/50000]\n","Training loop: loss: 1.750218  [19200/50000]\n","Training loop: loss: 1.612798  [22400/50000]\n","Training loop: loss: 1.560280  [25600/50000]\n","Training loop: loss: 1.501059  [28800/50000]\n","Training loop: loss: 1.676491  [32000/50000]\n","Training loop: loss: 1.695274  [35200/50000]\n","Training loop: loss: 1.863667  [38400/50000]\n","Training loop: loss: 1.452743  [41600/50000]\n","Training loop: loss: 1.670182  [44800/50000]\n","Training loop: loss: 2.054883  [48000/50000]\n","Training Accuracy: 43.9%\n","Testing Accuracy: 44.0%, Avg loss: 1.605698 \n","\n","Epoch 7\n","-------------------------------\n","Training loop: loss: 1.709365  [    0/50000]\n","Training loop: loss: 1.639163  [ 3200/50000]\n","Training loop: loss: 1.573617  [ 6400/50000]\n","Training loop: loss: 1.486475  [ 9600/50000]\n","Training loop: loss: 1.366605  [12800/50000]\n","Training loop: loss: 1.385957  [16000/50000]\n","Training loop: loss: 1.740642  [19200/50000]\n","Training loop: loss: 1.596317  [22400/50000]\n","Training loop: loss: 1.517331  [25600/50000]\n","Training loop: loss: 1.466274  [28800/50000]\n","Training loop: loss: 1.665958  [32000/50000]\n","Training loop: loss: 1.686065  [35200/50000]\n","Training loop: loss: 1.846038  [38400/50000]\n","Training loop: loss: 1.409246  [41600/50000]\n","Training loop: loss: 1.652827  [44800/50000]\n","Training loop: loss: 2.045741  [48000/50000]\n","Training Accuracy: 44.6%\n","Testing Accuracy: 44.9%, Avg loss: 1.583841 \n","\n","Epoch 8\n","-------------------------------\n","Training loop: loss: 1.688130  [    0/50000]\n","Training loop: loss: 1.620986  [ 3200/50000]\n","Training loop: loss: 1.555934  [ 6400/50000]\n","Training loop: loss: 1.466442  [ 9600/50000]\n","Training loop: loss: 1.355431  [12800/50000]\n","Training loop: loss: 1.359203  [16000/50000]\n","Training loop: loss: 1.735460  [19200/50000]\n","Training loop: loss: 1.595768  [22400/50000]\n","Training loop: loss: 1.478670  [25600/50000]\n","Training loop: loss: 1.440053  [28800/50000]\n","Training loop: loss: 1.648445  [32000/50000]\n","Training loop: loss: 1.677601  [35200/50000]\n","Training loop: loss: 1.839342  [38400/50000]\n","Training loop: loss: 1.369952  [41600/50000]\n","Training loop: loss: 1.634720  [44800/50000]\n","Training loop: loss: 2.037340  [48000/50000]\n","Training Accuracy: 45.4%\n","Testing Accuracy: 45.4%, Avg loss: 1.566271 \n","\n","Epoch 9\n","-------------------------------\n","Training loop: loss: 1.682528  [    0/50000]\n","Training loop: loss: 1.610320  [ 3200/50000]\n","Training loop: loss: 1.530152  [ 6400/50000]\n","Training loop: loss: 1.442755  [ 9600/50000]\n","Training loop: loss: 1.329716  [12800/50000]\n","Training loop: loss: 1.332395  [16000/50000]\n","Training loop: loss: 1.748331  [19200/50000]\n","Training loop: loss: 1.579410  [22400/50000]\n","Training loop: loss: 1.440820  [25600/50000]\n","Training loop: loss: 1.412565  [28800/50000]\n","Training loop: loss: 1.634625  [32000/50000]\n","Training loop: loss: 1.659649  [35200/50000]\n","Training loop: loss: 1.833817  [38400/50000]\n","Training loop: loss: 1.350044  [41600/50000]\n","Training loop: loss: 1.621894  [44800/50000]\n","Training loop: loss: 2.041241  [48000/50000]\n","Training Accuracy: 46.3%\n","Testing Accuracy: 45.7%, Avg loss: 1.553763 \n","\n","Epoch 10\n","-------------------------------\n","Training loop: loss: 1.666952  [    0/50000]\n","Training loop: loss: 1.588183  [ 3200/50000]\n","Training loop: loss: 1.489209  [ 6400/50000]\n","Training loop: loss: 1.424027  [ 9600/50000]\n","Training loop: loss: 1.297582  [12800/50000]\n","Training loop: loss: 1.321160  [16000/50000]\n","Training loop: loss: 1.737682  [19200/50000]\n","Training loop: loss: 1.580269  [22400/50000]\n","Training loop: loss: 1.411675  [25600/50000]\n","Training loop: loss: 1.387640  [28800/50000]\n","Training loop: loss: 1.617422  [32000/50000]\n","Training loop: loss: 1.654763  [35200/50000]\n","Training loop: loss: 1.824992  [38400/50000]\n","Training loop: loss: 1.310473  [41600/50000]\n","Training loop: loss: 1.618035  [44800/50000]\n","Training loop: loss: 2.043969  [48000/50000]\n","Training Accuracy: 46.8%\n","Testing Accuracy: 46.2%, Avg loss: 1.541126 \n","\n","Epoch 11\n","-------------------------------\n","Training loop: loss: 1.641278  [    0/50000]\n","Training loop: loss: 1.563609  [ 3200/50000]\n","Training loop: loss: 1.457100  [ 6400/50000]\n","Training loop: loss: 1.395039  [ 9600/50000]\n","Training loop: loss: 1.278946  [12800/50000]\n","Training loop: loss: 1.304689  [16000/50000]\n","Training loop: loss: 1.727149  [19200/50000]\n","Training loop: loss: 1.560480  [22400/50000]\n","Training loop: loss: 1.387752  [25600/50000]\n","Training loop: loss: 1.370572  [28800/50000]\n","Training loop: loss: 1.618287  [32000/50000]\n","Training loop: loss: 1.639332  [35200/50000]\n","Training loop: loss: 1.802793  [38400/50000]\n","Training loop: loss: 1.289552  [41600/50000]\n","Training loop: loss: 1.625400  [44800/50000]\n","Training loop: loss: 2.025847  [48000/50000]\n","Training Accuracy: 47.4%\n","Testing Accuracy: 46.6%, Avg loss: 1.531681 \n","\n","Epoch 12\n","-------------------------------\n","Training loop: loss: 1.625465  [    0/50000]\n","Training loop: loss: 1.532795  [ 3200/50000]\n","Training loop: loss: 1.441253  [ 6400/50000]\n","Training loop: loss: 1.371471  [ 9600/50000]\n","Training loop: loss: 1.253191  [12800/50000]\n","Training loop: loss: 1.288683  [16000/50000]\n","Training loop: loss: 1.706852  [19200/50000]\n","Training loop: loss: 1.535129  [22400/50000]\n","Training loop: loss: 1.375969  [25600/50000]\n","Training loop: loss: 1.343742  [28800/50000]\n","Training loop: loss: 1.607189  [32000/50000]\n","Training loop: loss: 1.630315  [35200/50000]\n","Training loop: loss: 1.778944  [38400/50000]\n","Training loop: loss: 1.265922  [41600/50000]\n","Training loop: loss: 1.625846  [44800/50000]\n","Training loop: loss: 2.026763  [48000/50000]\n","Training Accuracy: 47.9%\n","Testing Accuracy: 46.9%, Avg loss: 1.521116 \n","\n","Epoch 13\n","-------------------------------\n","Training loop: loss: 1.614070  [    0/50000]\n","Training loop: loss: 1.529718  [ 3200/50000]\n","Training loop: loss: 1.421711  [ 6400/50000]\n","Training loop: loss: 1.347105  [ 9600/50000]\n","Training loop: loss: 1.242599  [12800/50000]\n","Training loop: loss: 1.275735  [16000/50000]\n","Training loop: loss: 1.706009  [19200/50000]\n","Training loop: loss: 1.518005  [22400/50000]\n","Training loop: loss: 1.354215  [25600/50000]\n","Training loop: loss: 1.330521  [28800/50000]\n","Training loop: loss: 1.595443  [32000/50000]\n","Training loop: loss: 1.616619  [35200/50000]\n","Training loop: loss: 1.785488  [38400/50000]\n","Training loop: loss: 1.241912  [41600/50000]\n","Training loop: loss: 1.627712  [44800/50000]\n","Training loop: loss: 2.025223  [48000/50000]\n","Training Accuracy: 48.5%\n","Testing Accuracy: 47.1%, Avg loss: 1.511310 \n","\n","Epoch 14\n","-------------------------------\n","Training loop: loss: 1.592491  [    0/50000]\n","Training loop: loss: 1.496682  [ 3200/50000]\n","Training loop: loss: 1.405720  [ 6400/50000]\n","Training loop: loss: 1.333285  [ 9600/50000]\n","Training loop: loss: 1.226037  [12800/50000]\n","Training loop: loss: 1.259947  [16000/50000]\n","Training loop: loss: 1.690811  [19200/50000]\n","Training loop: loss: 1.502556  [22400/50000]\n","Training loop: loss: 1.339507  [25600/50000]\n","Training loop: loss: 1.314457  [28800/50000]\n","Training loop: loss: 1.574602  [32000/50000]\n","Training loop: loss: 1.602255  [35200/50000]\n","Training loop: loss: 1.769563  [38400/50000]\n","Training loop: loss: 1.222876  [41600/50000]\n","Training loop: loss: 1.619837  [44800/50000]\n","Training loop: loss: 2.023049  [48000/50000]\n","Training Accuracy: 48.9%\n","Testing Accuracy: 47.2%, Avg loss: 1.503451 \n","\n","Epoch 15\n","-------------------------------\n","Training loop: loss: 1.567423  [    0/50000]\n","Training loop: loss: 1.482827  [ 3200/50000]\n","Training loop: loss: 1.390432  [ 6400/50000]\n","Training loop: loss: 1.327003  [ 9600/50000]\n","Training loop: loss: 1.212341  [12800/50000]\n","Training loop: loss: 1.249175  [16000/50000]\n","Training loop: loss: 1.678955  [19200/50000]\n","Training loop: loss: 1.499637  [22400/50000]\n","Training loop: loss: 1.324305  [25600/50000]\n","Training loop: loss: 1.300918  [28800/50000]\n","Training loop: loss: 1.563703  [32000/50000]\n","Training loop: loss: 1.598405  [35200/50000]\n","Training loop: loss: 1.761785  [38400/50000]\n","Training loop: loss: 1.207092  [41600/50000]\n","Training loop: loss: 1.612296  [44800/50000]\n","Training loop: loss: 2.020936  [48000/50000]\n","Training Accuracy: 49.3%\n","Testing Accuracy: 47.6%, Avg loss: 1.495955 \n","\n","Epoch 16\n","-------------------------------\n","Training loop: loss: 1.553303  [    0/50000]\n","Training loop: loss: 1.480793  [ 3200/50000]\n","Training loop: loss: 1.377528  [ 6400/50000]\n","Training loop: loss: 1.322014  [ 9600/50000]\n","Training loop: loss: 1.208068  [12800/50000]\n","Training loop: loss: 1.232555  [16000/50000]\n","Training loop: loss: 1.662909  [19200/50000]\n","Training loop: loss: 1.484426  [22400/50000]\n","Training loop: loss: 1.312264  [25600/50000]\n","Training loop: loss: 1.282924  [28800/50000]\n","Training loop: loss: 1.547252  [32000/50000]\n","Training loop: loss: 1.598623  [35200/50000]\n","Training loop: loss: 1.751251  [38400/50000]\n","Training loop: loss: 1.191558  [41600/50000]\n","Training loop: loss: 1.606944  [44800/50000]\n","Training loop: loss: 2.003273  [48000/50000]\n","Training Accuracy: 49.7%\n","Testing Accuracy: 47.6%, Avg loss: 1.487955 \n","\n","Epoch 17\n","-------------------------------\n","Training loop: loss: 1.535357  [    0/50000]\n","Training loop: loss: 1.464628  [ 3200/50000]\n","Training loop: loss: 1.368162  [ 6400/50000]\n","Training loop: loss: 1.322809  [ 9600/50000]\n","Training loop: loss: 1.200345  [12800/50000]\n","Training loop: loss: 1.221800  [16000/50000]\n","Training loop: loss: 1.652790  [19200/50000]\n","Training loop: loss: 1.478068  [22400/50000]\n","Training loop: loss: 1.308216  [25600/50000]\n","Training loop: loss: 1.261333  [28800/50000]\n","Training loop: loss: 1.541671  [32000/50000]\n","Training loop: loss: 1.588668  [35200/50000]\n","Training loop: loss: 1.734723  [38400/50000]\n","Training loop: loss: 1.183632  [41600/50000]\n","Training loop: loss: 1.597580  [44800/50000]\n","Training loop: loss: 1.999862  [48000/50000]\n","Training Accuracy: 50.1%\n","Testing Accuracy: 48.0%, Avg loss: 1.481124 \n","\n","Epoch 18\n","-------------------------------\n","Training loop: loss: 1.512204  [    0/50000]\n","Training loop: loss: 1.446325  [ 3200/50000]\n","Training loop: loss: 1.351153  [ 6400/50000]\n","Training loop: loss: 1.316807  [ 9600/50000]\n","Training loop: loss: 1.197175  [12800/50000]\n","Training loop: loss: 1.212531  [16000/50000]\n","Training loop: loss: 1.655000  [19200/50000]\n","Training loop: loss: 1.478396  [22400/50000]\n","Training loop: loss: 1.296052  [25600/50000]\n","Training loop: loss: 1.252309  [28800/50000]\n","Training loop: loss: 1.528069  [32000/50000]\n","Training loop: loss: 1.584848  [35200/50000]\n","Training loop: loss: 1.724692  [38400/50000]\n","Training loop: loss: 1.172743  [41600/50000]\n","Training loop: loss: 1.584147  [44800/50000]\n","Training loop: loss: 1.986608  [48000/50000]\n","Training Accuracy: 50.5%\n","Testing Accuracy: 48.3%, Avg loss: 1.475737 \n","\n","Epoch 19\n","-------------------------------\n","Training loop: loss: 1.499940  [    0/50000]\n","Training loop: loss: 1.421631  [ 3200/50000]\n","Training loop: loss: 1.345098  [ 6400/50000]\n","Training loop: loss: 1.301236  [ 9600/50000]\n","Training loop: loss: 1.190928  [12800/50000]\n","Training loop: loss: 1.208405  [16000/50000]\n","Training loop: loss: 1.631706  [19200/50000]\n","Training loop: loss: 1.461547  [22400/50000]\n","Training loop: loss: 1.287116  [25600/50000]\n","Training loop: loss: 1.241440  [28800/50000]\n","Training loop: loss: 1.523390  [32000/50000]\n","Training loop: loss: 1.582264  [35200/50000]\n","Training loop: loss: 1.717660  [38400/50000]\n","Training loop: loss: 1.160802  [41600/50000]\n","Training loop: loss: 1.575428  [44800/50000]\n","Training loop: loss: 1.975723  [48000/50000]\n","Training Accuracy: 50.8%\n","Testing Accuracy: 48.4%, Avg loss: 1.470599 \n","\n","Epoch 20\n","-------------------------------\n","Training loop: loss: 1.485800  [    0/50000]\n","Training loop: loss: 1.397416  [ 3200/50000]\n","Training loop: loss: 1.330401  [ 6400/50000]\n","Training loop: loss: 1.293653  [ 9600/50000]\n","Training loop: loss: 1.190375  [12800/50000]\n","Training loop: loss: 1.185624  [16000/50000]\n","Training loop: loss: 1.619967  [19200/50000]\n","Training loop: loss: 1.445047  [22400/50000]\n","Training loop: loss: 1.282542  [25600/50000]\n","Training loop: loss: 1.229835  [28800/50000]\n","Training loop: loss: 1.514415  [32000/50000]\n","Training loop: loss: 1.572652  [35200/50000]\n","Training loop: loss: 1.703568  [38400/50000]\n","Training loop: loss: 1.155606  [41600/50000]\n","Training loop: loss: 1.576598  [44800/50000]\n","Training loop: loss: 1.956419  [48000/50000]\n","Training Accuracy: 51.2%\n","Testing Accuracy: 48.6%, Avg loss: 1.464337 \n","\n","Epoch 21\n","-------------------------------\n","Training loop: loss: 1.477090  [    0/50000]\n","Training loop: loss: 1.385754  [ 3200/50000]\n","Training loop: loss: 1.327557  [ 6400/50000]\n","Training loop: loss: 1.283599  [ 9600/50000]\n","Training loop: loss: 1.184237  [12800/50000]\n","Training loop: loss: 1.176890  [16000/50000]\n","Training loop: loss: 1.617466  [19200/50000]\n","Training loop: loss: 1.430861  [22400/50000]\n","Training loop: loss: 1.276510  [25600/50000]\n","Training loop: loss: 1.224584  [28800/50000]\n","Training loop: loss: 1.504657  [32000/50000]\n","Training loop: loss: 1.562783  [35200/50000]\n","Training loop: loss: 1.695767  [38400/50000]\n","Training loop: loss: 1.147217  [41600/50000]\n","Training loop: loss: 1.563192  [44800/50000]\n","Training loop: loss: 1.948956  [48000/50000]\n","Training Accuracy: 51.5%\n","Testing Accuracy: 48.6%, Avg loss: 1.460074 \n","\n","Epoch 22\n","-------------------------------\n","Training loop: loss: 1.462874  [    0/50000]\n","Training loop: loss: 1.378069  [ 3200/50000]\n","Training loop: loss: 1.314666  [ 6400/50000]\n","Training loop: loss: 1.273165  [ 9600/50000]\n","Training loop: loss: 1.187905  [12800/50000]\n","Training loop: loss: 1.169343  [16000/50000]\n","Training loop: loss: 1.614385  [19200/50000]\n","Training loop: loss: 1.420425  [22400/50000]\n","Training loop: loss: 1.268465  [25600/50000]\n","Training loop: loss: 1.212968  [28800/50000]\n","Training loop: loss: 1.504948  [32000/50000]\n","Training loop: loss: 1.548613  [35200/50000]\n","Training loop: loss: 1.683373  [38400/50000]\n","Training loop: loss: 1.139797  [41600/50000]\n","Training loop: loss: 1.558353  [44800/50000]\n","Training loop: loss: 1.931865  [48000/50000]\n","Training Accuracy: 51.8%\n","Testing Accuracy: 48.9%, Avg loss: 1.454635 \n","\n","Epoch 23\n","-------------------------------\n","Training loop: loss: 1.446688  [    0/50000]\n","Training loop: loss: 1.376726  [ 3200/50000]\n","Training loop: loss: 1.304742  [ 6400/50000]\n","Training loop: loss: 1.257985  [ 9600/50000]\n","Training loop: loss: 1.181409  [12800/50000]\n","Training loop: loss: 1.160198  [16000/50000]\n","Training loop: loss: 1.591955  [19200/50000]\n","Training loop: loss: 1.414030  [22400/50000]\n","Training loop: loss: 1.252235  [25600/50000]\n","Training loop: loss: 1.200167  [28800/50000]\n","Training loop: loss: 1.490625  [32000/50000]\n","Training loop: loss: 1.545954  [35200/50000]\n","Training loop: loss: 1.679368  [38400/50000]\n","Training loop: loss: 1.127342  [41600/50000]\n","Training loop: loss: 1.549785  [44800/50000]\n","Training loop: loss: 1.911478  [48000/50000]\n","Training Accuracy: 52.3%\n","Testing Accuracy: 48.9%, Avg loss: 1.449800 \n","\n","Epoch 24\n","-------------------------------\n","Training loop: loss: 1.439129  [    0/50000]\n","Training loop: loss: 1.366009  [ 3200/50000]\n","Training loop: loss: 1.297009  [ 6400/50000]\n","Training loop: loss: 1.250997  [ 9600/50000]\n","Training loop: loss: 1.182513  [12800/50000]\n","Training loop: loss: 1.155651  [16000/50000]\n","Training loop: loss: 1.584682  [19200/50000]\n","Training loop: loss: 1.410260  [22400/50000]\n","Training loop: loss: 1.242354  [25600/50000]\n","Training loop: loss: 1.197399  [28800/50000]\n","Training loop: loss: 1.491129  [32000/50000]\n","Training loop: loss: 1.543881  [35200/50000]\n","Training loop: loss: 1.653908  [38400/50000]\n","Training loop: loss: 1.124160  [41600/50000]\n","Training loop: loss: 1.557965  [44800/50000]\n","Training loop: loss: 1.894303  [48000/50000]\n","Training Accuracy: 52.5%\n","Testing Accuracy: 49.1%, Avg loss: 1.446365 \n","\n","Epoch 25\n","-------------------------------\n","Training loop: loss: 1.423280  [    0/50000]\n","Training loop: loss: 1.362366  [ 3200/50000]\n","Training loop: loss: 1.289269  [ 6400/50000]\n","Training loop: loss: 1.244888  [ 9600/50000]\n","Training loop: loss: 1.170573  [12800/50000]\n","Training loop: loss: 1.148142  [16000/50000]\n","Training loop: loss: 1.582833  [19200/50000]\n","Training loop: loss: 1.399818  [22400/50000]\n","Training loop: loss: 1.237956  [25600/50000]\n","Training loop: loss: 1.184353  [28800/50000]\n","Training loop: loss: 1.484780  [32000/50000]\n","Training loop: loss: 1.542512  [35200/50000]\n","Training loop: loss: 1.633918  [38400/50000]\n","Training loop: loss: 1.122035  [41600/50000]\n","Training loop: loss: 1.543436  [44800/50000]\n","Training loop: loss: 1.887621  [48000/50000]\n","Training Accuracy: 52.8%\n","Testing Accuracy: 49.3%, Avg loss: 1.442792 \n","\n","Epoch 26\n","-------------------------------\n","Training loop: loss: 1.416611  [    0/50000]\n","Training loop: loss: 1.339543  [ 3200/50000]\n","Training loop: loss: 1.277899  [ 6400/50000]\n","Training loop: loss: 1.226963  [ 9600/50000]\n","Training loop: loss: 1.170290  [12800/50000]\n","Training loop: loss: 1.140020  [16000/50000]\n","Training loop: loss: 1.565145  [19200/50000]\n","Training loop: loss: 1.385993  [22400/50000]\n","Training loop: loss: 1.227011  [25600/50000]\n","Training loop: loss: 1.179464  [28800/50000]\n","Training loop: loss: 1.472289  [32000/50000]\n","Training loop: loss: 1.543638  [35200/50000]\n","Training loop: loss: 1.626916  [38400/50000]\n","Training loop: loss: 1.115119  [41600/50000]\n","Training loop: loss: 1.539046  [44800/50000]\n","Training loop: loss: 1.878661  [48000/50000]\n","Training Accuracy: 53.0%\n","Testing Accuracy: 49.4%, Avg loss: 1.439779 \n","\n","Epoch 27\n","-------------------------------\n","Training loop: loss: 1.408612  [    0/50000]\n","Training loop: loss: 1.325689  [ 3200/50000]\n","Training loop: loss: 1.265359  [ 6400/50000]\n","Training loop: loss: 1.216807  [ 9600/50000]\n","Training loop: loss: 1.163506  [12800/50000]\n","Training loop: loss: 1.134725  [16000/50000]\n","Training loop: loss: 1.550823  [19200/50000]\n","Training loop: loss: 1.372348  [22400/50000]\n","Training loop: loss: 1.225894  [25600/50000]\n","Training loop: loss: 1.172071  [28800/50000]\n","Training loop: loss: 1.465703  [32000/50000]\n","Training loop: loss: 1.542165  [35200/50000]\n","Training loop: loss: 1.619457  [38400/50000]\n","Training loop: loss: 1.111680  [41600/50000]\n","Training loop: loss: 1.527174  [44800/50000]\n","Training loop: loss: 1.864015  [48000/50000]\n","Training Accuracy: 53.2%\n","Testing Accuracy: 49.5%, Avg loss: 1.435681 \n","\n","Epoch 28\n","-------------------------------\n","Training loop: loss: 1.395578  [    0/50000]\n","Training loop: loss: 1.318305  [ 3200/50000]\n","Training loop: loss: 1.258098  [ 6400/50000]\n","Training loop: loss: 1.203910  [ 9600/50000]\n","Training loop: loss: 1.150038  [12800/50000]\n","Training loop: loss: 1.130476  [16000/50000]\n","Training loop: loss: 1.536067  [19200/50000]\n","Training loop: loss: 1.370740  [22400/50000]\n","Training loop: loss: 1.214805  [25600/50000]\n","Training loop: loss: 1.171623  [28800/50000]\n","Training loop: loss: 1.449288  [32000/50000]\n","Training loop: loss: 1.540879  [35200/50000]\n","Training loop: loss: 1.609420  [38400/50000]\n","Training loop: loss: 1.109503  [41600/50000]\n","Training loop: loss: 1.518981  [44800/50000]\n","Training loop: loss: 1.851868  [48000/50000]\n","Training Accuracy: 53.5%\n","Testing Accuracy: 49.5%, Avg loss: 1.433662 \n","\n","Epoch 29\n","-------------------------------\n","Training loop: loss: 1.392144  [    0/50000]\n","Training loop: loss: 1.316894  [ 3200/50000]\n","Training loop: loss: 1.253207  [ 6400/50000]\n","Training loop: loss: 1.206447  [ 9600/50000]\n","Training loop: loss: 1.138996  [12800/50000]\n","Training loop: loss: 1.126124  [16000/50000]\n","Training loop: loss: 1.526356  [19200/50000]\n","Training loop: loss: 1.362503  [22400/50000]\n","Training loop: loss: 1.203568  [25600/50000]\n","Training loop: loss: 1.160689  [28800/50000]\n","Training loop: loss: 1.447374  [32000/50000]\n","Training loop: loss: 1.525356  [35200/50000]\n","Training loop: loss: 1.600165  [38400/50000]\n","Training loop: loss: 1.105582  [41600/50000]\n","Training loop: loss: 1.512202  [44800/50000]\n","Training loop: loss: 1.839297  [48000/50000]\n","Training Accuracy: 53.7%\n","Testing Accuracy: 49.6%, Avg loss: 1.430674 \n","\n","Epoch 30\n","-------------------------------\n","Training loop: loss: 1.386934  [    0/50000]\n","Training loop: loss: 1.304401  [ 3200/50000]\n","Training loop: loss: 1.252734  [ 6400/50000]\n","Training loop: loss: 1.192900  [ 9600/50000]\n","Training loop: loss: 1.133304  [12800/50000]\n","Training loop: loss: 1.119119  [16000/50000]\n","Training loop: loss: 1.520235  [19200/50000]\n","Training loop: loss: 1.355188  [22400/50000]\n","Training loop: loss: 1.198388  [25600/50000]\n","Training loop: loss: 1.148820  [28800/50000]\n","Training loop: loss: 1.435005  [32000/50000]\n","Training loop: loss: 1.533478  [35200/50000]\n","Training loop: loss: 1.598285  [38400/50000]\n","Training loop: loss: 1.100770  [41600/50000]\n","Training loop: loss: 1.500985  [44800/50000]\n","Training loop: loss: 1.823598  [48000/50000]\n","Training Accuracy: 54.0%\n","Testing Accuracy: 49.8%, Avg loss: 1.428887 \n","\n","Epoch 31\n","-------------------------------\n","Training loop: loss: 1.376089  [    0/50000]\n","Training loop: loss: 1.305020  [ 3200/50000]\n","Training loop: loss: 1.239616  [ 6400/50000]\n","Training loop: loss: 1.184270  [ 9600/50000]\n","Training loop: loss: 1.122907  [12800/50000]\n","Training loop: loss: 1.104776  [16000/50000]\n","Training loop: loss: 1.512554  [19200/50000]\n","Training loop: loss: 1.349818  [22400/50000]\n","Training loop: loss: 1.182349  [25600/50000]\n","Training loop: loss: 1.144936  [28800/50000]\n","Training loop: loss: 1.425992  [32000/50000]\n","Training loop: loss: 1.525870  [35200/50000]\n","Training loop: loss: 1.591600  [38400/50000]\n","Training loop: loss: 1.098067  [41600/50000]\n","Training loop: loss: 1.496221  [44800/50000]\n","Training loop: loss: 1.823133  [48000/50000]\n","Training Accuracy: 54.3%\n","Testing Accuracy: 49.8%, Avg loss: 1.427535 \n","\n","Epoch 32\n","-------------------------------\n","Training loop: loss: 1.371159  [    0/50000]\n","Training loop: loss: 1.308820  [ 3200/50000]\n","Training loop: loss: 1.239099  [ 6400/50000]\n","Training loop: loss: 1.181336  [ 9600/50000]\n","Training loop: loss: 1.118615  [12800/50000]\n","Training loop: loss: 1.095418  [16000/50000]\n","Training loop: loss: 1.498480  [19200/50000]\n","Training loop: loss: 1.349814  [22400/50000]\n","Training loop: loss: 1.180560  [25600/50000]\n","Training loop: loss: 1.131811  [28800/50000]\n","Training loop: loss: 1.417922  [32000/50000]\n","Training loop: loss: 1.514516  [35200/50000]\n","Training loop: loss: 1.589391  [38400/50000]\n","Training loop: loss: 1.092475  [41600/50000]\n","Training loop: loss: 1.484018  [44800/50000]\n","Training loop: loss: 1.818748  [48000/50000]\n","Training Accuracy: 54.5%\n","Testing Accuracy: 49.9%, Avg loss: 1.425833 \n","\n","Epoch 33\n","-------------------------------\n","Training loop: loss: 1.356720  [    0/50000]\n","Training loop: loss: 1.299388  [ 3200/50000]\n","Training loop: loss: 1.230245  [ 6400/50000]\n","Training loop: loss: 1.174255  [ 9600/50000]\n","Training loop: loss: 1.116842  [12800/50000]\n","Training loop: loss: 1.089527  [16000/50000]\n","Training loop: loss: 1.485741  [19200/50000]\n","Training loop: loss: 1.335736  [22400/50000]\n","Training loop: loss: 1.180414  [25600/50000]\n","Training loop: loss: 1.123199  [28800/50000]\n","Training loop: loss: 1.404641  [32000/50000]\n","Training loop: loss: 1.512769  [35200/50000]\n","Training loop: loss: 1.585245  [38400/50000]\n","Training loop: loss: 1.087422  [41600/50000]\n","Training loop: loss: 1.480052  [44800/50000]\n","Training loop: loss: 1.811548  [48000/50000]\n","Training Accuracy: 54.7%\n","Testing Accuracy: 49.9%, Avg loss: 1.424469 \n","\n","Epoch 34\n","-------------------------------\n","Training loop: loss: 1.346280  [    0/50000]\n","Training loop: loss: 1.293744  [ 3200/50000]\n","Training loop: loss: 1.225493  [ 6400/50000]\n","Training loop: loss: 1.173403  [ 9600/50000]\n","Training loop: loss: 1.117405  [12800/50000]\n","Training loop: loss: 1.083278  [16000/50000]\n","Training loop: loss: 1.472653  [19200/50000]\n","Training loop: loss: 1.321748  [22400/50000]\n","Training loop: loss: 1.173086  [25600/50000]\n","Training loop: loss: 1.117650  [28800/50000]\n","Training loop: loss: 1.388017  [32000/50000]\n","Training loop: loss: 1.515806  [35200/50000]\n","Training loop: loss: 1.578517  [38400/50000]\n","Training loop: loss: 1.080494  [41600/50000]\n","Training loop: loss: 1.475276  [44800/50000]\n","Training loop: loss: 1.798304  [48000/50000]\n","Training Accuracy: 54.9%\n","Testing Accuracy: 49.9%, Avg loss: 1.423330 \n","\n","Epoch 35\n","-------------------------------\n","Training loop: loss: 1.339404  [    0/50000]\n","Training loop: loss: 1.284268  [ 3200/50000]\n","Training loop: loss: 1.222448  [ 6400/50000]\n","Training loop: loss: 1.163891  [ 9600/50000]\n","Training loop: loss: 1.104010  [12800/50000]\n","Training loop: loss: 1.074858  [16000/50000]\n","Training loop: loss: 1.462025  [19200/50000]\n","Training loop: loss: 1.318679  [22400/50000]\n","Training loop: loss: 1.176973  [25600/50000]\n","Training loop: loss: 1.105478  [28800/50000]\n","Training loop: loss: 1.376407  [32000/50000]\n","Training loop: loss: 1.521110  [35200/50000]\n","Training loop: loss: 1.565112  [38400/50000]\n","Training loop: loss: 1.073679  [41600/50000]\n","Training loop: loss: 1.472853  [44800/50000]\n","Training loop: loss: 1.792498  [48000/50000]\n","Training Accuracy: 55.1%\n","Testing Accuracy: 49.8%, Avg loss: 1.422994 \n","\n","Done!\n"]}],"source":["for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train_loop(train_dataloader, model, loss_fn, optimizer)\n","    test_loop(test_dataloader, model, loss_fn)\n","print(\"Done!\")"]},{"cell_type":"markdown","metadata":{"id":"9d2ca7b1"},"source":["## \u003cfont size='5'\u003e**III) Fine Tuning Hyperparameters**\u003c/font\u003e"]},{"cell_type":"markdown","metadata":{"id":"vtmexjmGFYTR"},"source":["Adjusting the hyperparameters and gaining a deeper understanding of how they impact the ultimate performance is a substantial aspect of working with neural networks. Therefore, we encourage you to gain practical experience in this regard."]},{"cell_type":"markdown","metadata":{"id":"7f79ae32"},"source":["In this task, your goal is to play around with different settings for various options like layer size, batch size, learning rate. You should also experiment with optimizer hyperparameters including momentum, weight decay and more.\n","\n","To understand how these choices affect your model's performance, you'll create at least three graphs. Each graph will show how changing one of these options (except for epochs) impacts how well your model learns and predicts."]},{"cell_type":"markdown","metadata":{"id":"x719wW9FIynX"},"source":["## \u003cfont size='4'\u003e**Example** - We've given you an example code for changing number of epochs so you can see how it's done.\u003c/font\u003e"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"olcxRr7T8bpj"},"outputs":[],"source":["learning_rate = 1e-3\n","batch_size = 64\n","epochs = [1, 5, 10, 15, 20, 25]\n","momentum = 0\n","weight_decay = 0\n","dampening = 0\n","\n","# Train and Test\n","test_accs = []\n","test_losses = []\n","training_accs = []\n","for e in epochs: #Would change this to reflect whatever hyperparameter you would be testing\n","    # Model\n","    model = CIFAR10Classifier().to(device)\n","    model.requires_grad_(True)\n","    # Optimizer\n","    optimizer = torch.optim.SGD(model.parameters(),\n","                            lr = learning_rate,\n","                            momentum = momentum,\n","                            weight_decay = weight_decay,\n","                            dampening= dampening)\n","    # Loss Func\n","    loss_fn = nn.CrossEntropyLoss()\n","    # Dataloaders\n","    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n","    test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","    final_train_acc = 0\n","    final_test_acc = 0\n","    final_test_loss = 0\n","    for t in range(e):\n","        # print(f\"Currently running epoch {t+1}\")\n","        training_acc = train_loop(train_dataloader, model, loss_fn, optimizer, print_log=False)\n","        testing_acc, test_loss =  test_loop(test_dataloader, model, loss_fn, print_log=False)\n","        final_test_acc = testing_acc\n","        final_test_loss = test_loss\n","        final_train_acc = training_acc\n","    test_accs.append(final_test_acc)\n","    test_losses.append(final_test_loss)\n","    training_accs.append(final_train_acc)\n","plt.plot(epochs,test_losses, color ='tab:red', label='testing loss')\n","plt.plot(epochs,test_accs, color ='tab:blue', label='testing accuracy')\n","plt.plot(epochs,training_accs, color ='tab:green', label='training accuracy')\n","plt.legend()\n","print(\"Done!\")"]},{"cell_type":"markdown","metadata":{"id":"w7Zi1npqHU7B"},"source":["\u003cfont size='4' color='Red'\u003eTask 1.3 - Experiment 1 (2 point)\u003c/font\u003e"]},{"cell_type":"markdown","metadata":{"id":"cd5IJznoH60y"},"source":["$$\\text{I am tuning learning_rate hyperparameter for better performance}$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8dRd98xpNX15"},"outputs":[],"source":["learning_rates = [1e-2, 1e-3, 1e-4, 1e-5]\n","batch_size = 64\n","epochs = 25\n","momentum = 0\n","weight_decay = 0\n","dampening = 0\n","\n","# Train and Test\n","test_accs = []\n","test_losses = []\n","training_accs = []\n","\n","# Define your CIFAR10Classifier model here\n","model = CIFAR10Classifier().to(device)\n","model.requires_grad_(True)\n","\n","# Loss Function\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# Dataloaders\n","train_dataloader = DataLoader(train_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","\n","for lr in learning_rates:\n","    # Optimizer (create a new optimizer for each learning rate)\n","    optimizer = torch.optim.SGD(model.parameters(),\n","                                lr=lr,\n","                                momentum=momentum,\n","                                weight_decay=weight_decay,\n","                                dampening=dampening)\n","\n","    final_train_acc = 0\n","    final_test_acc = 0\n","    final_test_loss = 0\n","\n","    for epoch in range(epochs):\n","        training_acc = train_loop(train_dataloader, model, loss_fn, optimizer, print_log=False)\n","        testing_acc, test_loss = test_loop(test_dataloader, model, loss_fn, print_log=False)\n","\n","        final_test_acc = testing_acc\n","        final_test_loss = test_loss\n","        final_train_acc = training_acc\n","\n","    test_accs.append(final_test_acc)\n","    test_losses.append(final_test_loss)\n","    training_accs.append(final_train_acc)\n","\n","plt.plot(learning_rates, test_losses, color='tab:red', label='testing loss')\n","plt.plot(learning_rates, test_accs, color='tab:blue', label='testing accuracy')\n","plt.plot(learning_rates, training_accs, color='tab:green', label='training accuracy')\n","plt.xscale('log')\n","plt.legend()\n","print(\"Done!\")"]},{"cell_type":"markdown","metadata":{"id":"bCXoR1dtIVqE"},"source":["\u003cfont size='4' color='Red'\u003eTask 1.3 - Experiment 2 (2 point)\u003c/font\u003e"]},{"cell_type":"markdown","metadata":{"id":"NBR25sGzIaqE"},"source":["$$\\text{I am tuning batch size hyperparameter for better performance}$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Xm_gZhsIaqP"},"outputs":[],"source":["learning_rate = 1e-3\n","batch_sizes = [16, 32, 64, 128]\n","epochs = 25\n","momentum = 0\n","weight_decay = 0\n","dampening = 0\n","test_accs = []\n","test_losses = []\n","training_accs = []\n","\n","# Loop over different batch sizes\n","for batch_size in batch_sizes:\n","    # Define your CIFAR10Classifier model here\n","    model = CIFAR10Classifier().to(device)\n","    model.requires_grad_(True)\n","\n","    # Optimizer (create a new optimizer for each batch size)\n","    optimizer = torch.optim.SGD(model.parameters(),\n","                                lr=learning_rate,\n","                                momentum=momentum,\n","                                weight_decay=weight_decay,\n","                                dampening=dampening)\n","\n","    final_train_acc = 0\n","    final_test_acc = 0\n","    final_test_loss = 0\n","\n","    # Dataloaders with the current batch size\n","    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n","    test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","\n","    for epoch in range(epochs):\n","        training_acc = train_loop(train_dataloader, model, loss_fn, optimizer, print_log=False)\n","        testing_acc, test_loss = test_loop(test_dataloader, model, loss_fn, print_log=False)\n","\n","        final_test_acc = testing_acc\n","        final_test_loss = test_loss\n","        final_train_acc = training_acc\n","\n","    # Append results for the current batch size\n","    test_accs.append(final_test_acc)\n","    test_losses.append(final_test_loss)\n","    training_accs.append(final_train_acc)\n","\n","# Now, you can plot the results for different batch sizes\n","plt.plot(batch_sizes, test_losses, color='tab:red', label='testing loss')\n","plt.plot(batch_sizes, test_accs, color='tab:blue', label='testing accuracy')\n","plt.plot(batch_sizes, training_accs, color='tab:green', label='training accuracy')\n","plt.xscale('log')\n","plt.legend()\n","print(\"Done!\")"]},{"cell_type":"markdown","metadata":{"id":"RXVjjad0IhZs"},"source":["\u003cfont size='4' color='Red'\u003eTask 1.4 - Experiment 3 (2 point)\u003c/font\u003e"]},{"cell_type":"markdown","metadata":{"id":"6NZyqrBXIhZs"},"source":["$$\\text{I am tuning momentum hyperparameter for better performance}$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XytrrMb3IhZs"},"outputs":[],"source":["momentum_values = [0.0, 0.5, 0.9, 0.95, 0.99]\n","learning_rate = 1e-3\n","batch_size = 64\n","epochs = 25\n","weight_decay = 0\n","dampening = 0\n","\n","# Train and Test\n","test_accs = []\n","test_losses = []\n","training_accs = []\n","\n","# Define your CIFAR10Classifier model here\n","model = CIFAR10Classifier().to(device)\n","model.requires_grad_(True)\n","\n","# Loss Function\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# Dataloaders\n","train_dataloader = DataLoader(train_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","\n","for momentum in momentum_values:\n","    # Optimizer (create a new optimizer for each learning rate)\n","    optimizer = torch.optim.SGD(model.parameters(),\n","                                lr = learning_rate,\n","                                momentum = momentum,\n","                                weight_decay = weight_decay,\n","                                dampening = dampening)\n","\n","    final_train_acc = 0\n","    final_test_acc = 0\n","    final_test_loss = 0\n","\n","    for epoch in range(epochs):\n","        training_acc = train_loop(train_dataloader, model, loss_fn, optimizer, print_log=False)\n","        testing_acc, test_loss = test_loop(test_dataloader, model, loss_fn, print_log=False)\n","\n","        final_test_acc = testing_acc\n","        final_test_loss = test_loss\n","        final_train_acc = training_acc\n","\n","    test_accs.append(final_test_acc)\n","    test_losses.append(final_test_loss)\n","    training_accs.append(final_train_acc)\n","\n","plt.plot(momentum_values, test_losses, color='tab:red', label='testing loss')\n","plt.plot(momentum_values, test_accs, color='tab:blue', label='testing accuracy')\n","plt.plot(momentum_values, training_accs, color='tab:green', label='training accuracy')\n","plt.legend()\n","print(\"Done!\")"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":5}